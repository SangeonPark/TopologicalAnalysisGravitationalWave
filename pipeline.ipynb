{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import GWAnalyzer\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['X', 'y']\n",
      "X shape: (384, 2, 3072)\n",
      "y shape: (384, 1)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"./data\"; file_name = \"batch.h5\"\n",
    "\n",
    "with h5py.File(f\"{DATA_DIR}/{file_name}\", \"r\") as f:\n",
    "\n",
    "    # Print the keys (groups and datasets) in the file\n",
    "    print(\"Keys:\", list(f.keys()))\n",
    "    arr = f['X'][:]\n",
    "    labels = f['y'][:]\n",
    "    \n",
    "    \n",
    "    print(\"X shape:\", arr.shape)\n",
    "    print(\"y shape:\", labels.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Topological Features and Save them as npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector1 = arr[:,0,:]\n",
    "detector2 = arr[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing spectrograms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ce56a9fac94e0b86d8e54ac49397fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of shape: (384, 1267, 3)\n",
      "Chunk Elapsed Time: 1.8660902976989746\n",
      "start processing point cloud features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901c9720fb034cd9aca3864a1376b332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of shape: (384, 3072)\n",
      "Chunk Elapsed Time: 99.34615445137024\n",
      "Shape of the final features is (384, 30)\n"
     ]
    }
   ],
   "source": [
    "gwana = GWAnalyzer(detector1)\n",
    "gwana.obtain_topological_features(True, True)\n",
    "gwana.save_features(os.getcwd(), \"detector1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing spectrograms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e89607717024b21be2b67dae2f99b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of shape: (384, 1395, 3)\n",
      "Chunk Elapsed Time: 2.1024577617645264\n",
      "start processing point cloud features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fab043843d46a3a95639468ec4f191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of shape: (384, 3072)\n",
      "Chunk Elapsed Time: 101.51838612556458\n",
      "Shape of the final features is (384, 30)\n"
     ]
    }
   ],
   "source": [
    "gwana = GWAnalyzer(detector2)\n",
    "gwana.obtain_topological_features(True, True)\n",
    "gwana.save_features(os.getcwd(), \"detector2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangeon/.local/lib/python3.8/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n",
      "/nobackup/users/sangeon/condas/anaconda3/envs/studies/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "import torch\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "feat_detector1 = np.load(f'{os.path.join(path, \"detector1\")}_topofeatures.npy')\n",
    "feat_detector2 = np.load(f'{os.path.join(path, \"detector2\")}_topofeatures.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat= np.column_stack([feat_detector1, feat_detector2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.squeeze(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((384, 60), (384,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = dataset_split(feat, labels, train_ratio = 0.6, val_ratio = 0.2, test_ratio = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {'train':train_dataset,\n",
    "             'val':val_dataset,\n",
    "             'test':test_dataset,\n",
    "             'predict':test_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import TabularDataModule, Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_dm = TabularDataModule(file_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(\"tabular\",\"MLP\", 1e-4, [60, 1, [200,100,50,50,50,20,10,5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CometLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in online mode\n"
     ]
    }
   ],
   "source": [
    "comet_logger = CometLogger(\n",
    "  api_key=\"CkkrVkSk6Vr2WKlbXIzlkhNlE\",\n",
    "  project_name=\"topogw\",\n",
    "  workspace=\"sangeonpark\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=50, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=os.getcwd(),\n",
    "    filename=\"Test-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback, TQDMProgressBar\n",
    "\n",
    "class PrintCallbacks(Callback):\n",
    "    def on_init_start(self, trainer):\n",
    "        print(\"Starting to init trainer!\")\n",
    "\n",
    "    def on_init_end(self, trainer):\n",
    "        print(\"Trainer is init now\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print(\"Training ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "class MyProgressBar(TQDMProgressBar):\n",
    "    def init_validation_tqdm(self):\n",
    "        bar = super().init_validation_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n",
    "    def init_predict_tqdm(self):\n",
    "        bar = super().init_predict_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n",
    "    def init_test_tqdm(self):\n",
    "        bar = super().init_test_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os \n",
    "#import pprint \n",
    "  \n",
    "# Get the list of user's \n",
    "#env_var = os.environ \n",
    "  \n",
    "# Print the list of user's \n",
    "#print(\"User's Environment variable:\") \n",
    "#pprint.pprint(dict(env_var), width = 1) \n",
    "\n",
    "# ONLY IF YOU ARE IN SLURM ENVIRONMENT\n",
    "#os.environ['SLURM_NTASKS_PER_NODE'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(callbacks=[PrintCallbacks(),MyProgressBar(),early_stop_callback,checkpoint_callback],logger=comet_logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.tuner import Tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/users/sangeon/condas/anaconda3/envs/studies/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/sangeonpark/topogw/975a1e44ad934a96a99d702c5c60c557\n",
      "\n",
      "/nobackup/users/sangeon/condas/anaconda3/envs/studies/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/sangeon/TopologicalAnalysisGravitationalWave exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/nobackup/users/sangeon/condas/anaconda3/envs/studies/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:   2%|▏         | 2/100 [00:00<00:15,  6.23it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:   3%|▎         | 3/100 [00:00<00:19,  5.05it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:   4%|▍         | 4/100 [00:00<00:21,  4.54it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:   5%|▌         | 5/100 [00:01<00:21,  4.34it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:   6%|▌         | 6/100 [00:01<00:22,  4.11it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:   7%|▋         | 7/100 [00:01<00:23,  4.04it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:   8%|▊         | 8/100 [00:01<00:22,  4.03it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:   9%|▉         | 9/100 [00:02<00:22,  4.01it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  10%|█         | 10/100 [00:02<00:22,  3.96it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  11%|█         | 11/100 [00:02<00:22,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  12%|█▏        | 12/100 [00:02<00:22,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  13%|█▎        | 13/100 [00:03<00:22,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  14%|█▍        | 14/100 [00:03<00:22,  3.90it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  15%|█▌        | 15/100 [00:03<00:21,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  16%|█▌        | 16/100 [00:03<00:21,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  17%|█▋        | 17/100 [00:04<00:21,  3.94it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  18%|█▊        | 18/100 [00:04<00:21,  3.90it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  19%|█▉        | 19/100 [00:04<00:20,  3.92it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  20%|██        | 20/100 [00:04<00:20,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  21%|██        | 21/100 [00:05<00:20,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  22%|██▏       | 22/100 [00:05<00:19,  3.94it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  23%|██▎       | 23/100 [00:05<00:19,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  24%|██▍       | 24/100 [00:05<00:19,  3.94it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  25%|██▌       | 25/100 [00:06<00:18,  3.95it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  26%|██▌       | 26/100 [00:06<00:18,  3.96it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  27%|██▋       | 27/100 [00:06<00:18,  3.95it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  28%|██▊       | 28/100 [00:06<00:18,  3.97it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  29%|██▉       | 29/100 [00:07<00:18,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  30%|███       | 30/100 [00:07<00:17,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  31%|███       | 31/100 [00:07<00:17,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  32%|███▏      | 32/100 [00:07<00:17,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  33%|███▎      | 33/100 [00:08<00:17,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  34%|███▍      | 34/100 [00:08<00:16,  3.94it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  35%|███▌      | 35/100 [00:08<00:16,  3.87it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  36%|███▌      | 36/100 [00:09<00:16,  3.88it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  37%|███▋      | 37/100 [00:09<00:16,  3.85it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  38%|███▊      | 38/100 [00:09<00:15,  3.88it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  39%|███▉      | 39/100 [00:09<00:15,  3.87it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  40%|████      | 40/100 [00:10<00:15,  3.85it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  41%|████      | 41/100 [00:10<00:15,  3.88it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  42%|████▏     | 42/100 [00:10<00:14,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  43%|████▎     | 43/100 [00:10<00:14,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  44%|████▍     | 44/100 [00:11<00:14,  3.92it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  45%|████▌     | 45/100 [00:11<00:13,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  46%|████▌     | 46/100 [00:11<00:13,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  47%|████▋     | 47/100 [00:11<00:13,  3.92it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  48%|████▊     | 48/100 [00:12<00:13,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  49%|████▉     | 49/100 [00:12<00:13,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  50%|█████     | 50/100 [00:12<00:12,  3.88it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  51%|█████     | 51/100 [00:12<00:12,  3.84it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  52%|█████▏    | 52/100 [00:13<00:12,  3.85it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  53%|█████▎    | 53/100 [00:13<00:12,  3.89it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  54%|█████▍    | 54/100 [00:13<00:11,  3.92it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  55%|█████▌    | 55/100 [00:13<00:11,  3.89it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  56%|█████▌    | 56/100 [00:14<00:11,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  57%|█████▋    | 57/100 [00:14<00:11,  3.90it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  58%|█████▊    | 58/100 [00:14<00:10,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  59%|█████▉    | 59/100 [00:14<00:10,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  60%|██████    | 60/100 [00:15<00:10,  3.95it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  61%|██████    | 61/100 [00:15<00:09,  3.97it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  62%|██████▏   | 62/100 [00:15<00:09,  3.98it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  63%|██████▎   | 63/100 [00:15<00:09,  3.99it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  64%|██████▍   | 64/100 [00:16<00:09,  3.98it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  65%|██████▌   | 65/100 [00:16<00:08,  3.96it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  66%|██████▌   | 66/100 [00:16<00:08,  3.94it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  67%|██████▋   | 67/100 [00:16<00:08,  3.92it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  68%|██████▊   | 68/100 [00:17<00:08,  3.94it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  69%|██████▉   | 69/100 [00:17<00:07,  3.94it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  70%|███████   | 70/100 [00:17<00:07,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  71%|███████   | 71/100 [00:17<00:07,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  72%|███████▏  | 72/100 [00:18<00:07,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  73%|███████▎  | 73/100 [00:18<00:06,  3.94it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  74%|███████▍  | 74/100 [00:18<00:06,  3.90it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  75%|███████▌  | 75/100 [00:18<00:06,  3.92it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  76%|███████▌  | 76/100 [00:19<00:06,  3.90it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  77%|███████▋  | 77/100 [00:19<00:05,  3.89it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  78%|███████▊  | 78/100 [00:19<00:05,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  79%|███████▉  | 79/100 [00:19<00:05,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  80%|████████  | 80/100 [00:20<00:05,  3.95it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  81%|████████  | 81/100 [00:20<00:04,  3.92it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  82%|████████▏ | 82/100 [00:20<00:04,  3.89it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  83%|████████▎ | 83/100 [00:21<00:04,  3.90it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  84%|████████▍ | 84/100 [00:21<00:04,  3.92it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  85%|████████▌ | 85/100 [00:21<00:03,  3.87it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  86%|████████▌ | 86/100 [00:21<00:03,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  87%|████████▋ | 87/100 [00:22<00:03,  3.92it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  88%|████████▊ | 88/100 [00:22<00:03,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  89%|████████▉ | 89/100 [00:22<00:02,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  90%|█████████ | 90/100 [00:22<00:02,  3.88it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  91%|█████████ | 91/100 [00:23<00:02,  3.88it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  92%|█████████▏| 92/100 [00:23<00:02,  3.91it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  93%|█████████▎| 93/100 [00:23<00:01,  3.90it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  94%|█████████▍| 94/100 [00:23<00:01,  3.93it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  95%|█████████▌| 95/100 [00:24<00:01,  3.95it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  96%|█████████▌| 96/100 [00:24<00:01,  3.96it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  97%|█████████▋| 97/100 [00:24<00:00,  3.97it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  98%|█████████▊| 98/100 [00:24<00:00,  3.95it/s]\n",
      "\n",
      "\u001b[A\u001b[Ag best initial lr:  99%|█████████▉| 99/100 [00:25<00:00,  3.94it/s]\n",
      "\n",
      "\u001b[A\u001b[A`Trainer.fit` stopped: `max_steps=100` reached.:25<00:00,  3.94it/s]\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:25<00:00,  3.93it/s]\n",
      "Learning rate set to 0.13182567385564073\n",
      "Restoring states from the checkpoint path at /home/sangeon/TopologicalAnalysisGravitationalWave/.lr_find_d4193c89-9917-4338-be8b-d56c035b3d44.ckpt\n",
      "Restored all states from the checkpoint at /home/sangeon/TopologicalAnalysisGravitationalWave/.lr_find_d4193c89-9917-4338-be8b-d56c035b3d44.ckpt\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO: Comet.ml ExistingExperiment Summary\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/sangeonpark/topogw/975a1e44ad934a96a99d702c5c60c557\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     loss [10] : (0.5813172459602356, 0.6309957504272461)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Created from : pytorch-lightning\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.tuner.lr_finder._LRFinder at 0x2000ec6a88e0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.lr_find(model, datamodule=tabular_dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/sangeonpark/topogw/975a1e44ad934a96a99d702c5c60c557\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type    | Params\n",
      "---------------------------------------\n",
      "0 | activation | Sigmoid | 0     \n",
      "1 | loss       | BCELoss | 0     \n",
      "2 | layers     | MLP     | 44.7 K\n",
      "---------------------------------------\n",
      "44.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "44.7 K    Total params\n",
      "0.179     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 28.79it/s, v_num=c557, train_loss=0.581]\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=c557, train_loss=0.590, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=c557, train_loss=0.585, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=c557, train_loss=0.607, val_loss_step=0.659, val_loss_epoch=0.659]\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=c557, train_loss=0.588, val_loss_step=0.659, val_loss_epoch=0.659]\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=c557, train_loss=0.594, val_loss_step=0.659, val_loss_epoch=0.659]\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=c557, train_loss=0.610, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=c557, train_loss=0.584, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=c557, train_loss=0.622, val_loss_step=0.659, val_loss_epoch=0.659]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=c557, train_loss=0.587, val_loss_step=0.659, val_loss_epoch=0.659]\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=c557, train_loss=0.593, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=c557, train_loss=0.573, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=c557, train_loss=0.578, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=c557, train_loss=0.577, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=c557, train_loss=0.559, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=c557, train_loss=0.574, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=c557, train_loss=0.594, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=c557, train_loss=0.572, val_loss_step=0.659, val_loss_epoch=0.659]\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=c557, train_loss=2.000, val_loss_step=0.660, val_loss_epoch=0.660]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=c557, train_loss=0.577, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=c557, train_loss=0.581, val_loss_step=0.658, val_loss_epoch=0.658]\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=c557, train_loss=0.584, val_loss_step=0.660, val_loss_epoch=0.660]\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=c557, train_loss=0.583, val_loss_step=0.662, val_loss_epoch=0.662]\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=c557, train_loss=0.582, val_loss_step=0.662, val_loss_epoch=0.662]\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=c557, train_loss=0.584, val_loss_step=0.663, val_loss_epoch=0.663]\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=c557, train_loss=0.602, val_loss_step=0.663, val_loss_epoch=0.663]\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=c557, train_loss=0.587, val_loss_step=0.663, val_loss_epoch=0.663]\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=c557, train_loss=0.587, val_loss_step=0.662, val_loss_epoch=0.662]\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=c557, train_loss=0.581, val_loss_step=0.662, val_loss_epoch=0.662]\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=c557, train_loss=0.574, val_loss_step=0.661, val_loss_epoch=0.661]\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=c557, train_loss=0.584, val_loss_step=0.660, val_loss_epoch=0.660]\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=c557, train_loss=0.582, val_loss_step=0.659, val_loss_epoch=0.659]\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=c557, train_loss=0.583, val_loss_step=0.659, val_loss_epoch=0.659]\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=c557, train_loss=0.575, val_loss_step=0.660, val_loss_epoch=0.660]\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=c557, train_loss=0.589, val_loss_step=0.661, val_loss_epoch=0.661]\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=c557, train_loss=0.583, val_loss_step=0.663, val_loss_epoch=0.663]\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=c557, train_loss=0.584, val_loss_step=0.667, val_loss_epoch=0.667]\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=c557, train_loss=0.580, val_loss_step=0.675, val_loss_epoch=0.675]\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=c557, train_loss=0.593, val_loss_step=0.684, val_loss_epoch=0.684]\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=c557, train_loss=0.582, val_loss_step=0.707, val_loss_epoch=0.707]\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=c557, train_loss=0.586, val_loss_step=0.739, val_loss_epoch=0.739]\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=c557, train_loss=0.592, val_loss_step=0.761, val_loss_epoch=0.761]\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=c557, train_loss=0.600, val_loss_step=0.780, val_loss_epoch=0.780]\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=c557, train_loss=0.586, val_loss_step=0.810, val_loss_epoch=0.810]\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=c557, train_loss=0.585, val_loss_step=0.845, val_loss_epoch=0.845]\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=c557, train_loss=0.583, val_loss_step=0.871, val_loss_epoch=0.871]\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=c557, train_loss=0.575, val_loss_step=0.909, val_loss_epoch=0.909]\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=c557, train_loss=0.573, val_loss_step=0.949, val_loss_epoch=0.949]\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=c557, train_loss=0.588, val_loss_step=0.948, val_loss_epoch=0.948]\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=c557, train_loss=0.587, val_loss_step=0.917, val_loss_epoch=0.917]\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=c557, train_loss=0.598, val_loss_step=0.894, val_loss_epoch=0.894]\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=c557, train_loss=0.585, val_loss_step=0.928, val_loss_epoch=0.928]\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=c557, train_loss=0.596, val_loss_step=0.955, val_loss_epoch=0.955]\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=c557, train_loss=0.591, val_loss_step=0.988, val_loss_epoch=0.988]\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=c557, train_loss=0.583, val_loss_step=0.980, val_loss_epoch=0.980]\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=c557, train_loss=0.583, val_loss_step=0.950, val_loss_epoch=0.950]\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=c557, train_loss=0.585, val_loss_step=0.944, val_loss_epoch=0.944]\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=c557, train_loss=0.593, val_loss_step=0.930, val_loss_epoch=0.930]\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=c557, train_loss=0.570, val_loss_step=0.927, val_loss_epoch=0.927]\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=c557, train_loss=0.566, val_loss_step=0.964, val_loss_epoch=0.964]\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=c557, train_loss=0.582, val_loss_step=0.982, val_loss_epoch=0.982]\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=c557, train_loss=0.572, val_loss_step=0.988, val_loss_epoch=0.988]\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=c557, train_loss=0.592, val_loss_step=1.020, val_loss_epoch=1.020]\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=c557, train_loss=0.561, val_loss_step=0.999, val_loss_epoch=0.999]\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=c557, train_loss=0.579, val_loss_step=0.973, val_loss_epoch=0.973]\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=c557, train_loss=0.575, val_loss_step=0.959, val_loss_epoch=0.959]\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=c557, train_loss=0.573, val_loss_step=0.943, val_loss_epoch=0.943]\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=c557, train_loss=0.593, val_loss_step=0.928, val_loss_epoch=0.928]\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=c557, train_loss=0.573, val_loss_step=0.970, val_loss_epoch=0.970]\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=c557, train_loss=0.601, val_loss_step=0.979, val_loss_epoch=0.979]\n",
      "Training ended|██████████| 1/1 [00:00<00:00,  3.46it/s, v_num=c557, train_loss=0.601, val_loss_step=1.020, val_loss_epoch=1.020]\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s, v_num=c557, train_loss=0.601, val_loss_step=1.020, val_loss_epoch=1.020]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: -----------------------------------\n",
      "COMET INFO: Comet.ml ExistingExperiment Summary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: -----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/sangeonpark/topogw/975a1e44ad934a96a99d702c5c60c557\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     loss [7]            : (0.5811454057693481, 0.5984839200973511)\n",
      "COMET INFO:     train_loss          : 0.5873777866363525\n",
      "COMET INFO:     val_loss_epoch [70] : (0.6580713987350464, 1.0218634605407715)\n",
      "COMET INFO:     val_loss_step [70]  : (0.6580713987350464, 1.0218634605407715)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Created from : pytorch-lightning\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     backbone_type : MLP\n",
      "COMET INFO:     data_type     : tabular\n",
      "COMET INFO:     learning_rate : 0.0001\n",
      "COMET INFO:     modelparams   : [60, 1, [200, 100, 50, 50, 50, 20, 10, 5]]\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     model graph : 1\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=tabular_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/sangeonpark/topogw/975a1e44ad934a96a99d702c5c60c557\n",
      "\n",
      "Restoring states from the checkpoint path at /home/sangeon/TopologicalAnalysisGravitationalWave/Test-epoch=19-val_loss=0.66.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/sangeon/TopologicalAnalysisGravitationalWave/Test-epoch=19-val_loss=0.66.ckpt\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "/nobackup/users/sangeon/condas/anaconda3/envs/studies/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: -----------------------------------\n",
      "COMET INFO: Comet.ml ExistingExperiment Summary\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/sangeonpark/topogw/975a1e44ad934a96a99d702c5c60c557\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Created from : pytorch-lightning\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     backbone_type : MLP\n",
      "COMET INFO:     data_type     : tabular\n",
      "COMET INFO:     learning_rate : 0.0001\n",
      "COMET INFO:     modelparams   : [60, 1, [200, 100, 50, 50, 50, 20, 10, 5]]\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     model graph : 1\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO: Uploading 21 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "predicted_list = trainer.predict(model, tabular_dm, ckpt_path='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predicted_list[0][0]\n",
    "label = predicted_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_preds = torch.round(torch.sigmoid(preds)).squeeze()\n",
    "correct = (rounded_preds == label).float() \n",
    "    # Calculate accuracy\n",
    "accuracy = correct.sum() / len(rounded_preds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True, False,  True,  True, False, False,\n",
       "        False, False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True, False, False, False,  True,  True,  True,  True,\n",
       "         True, False, False,  True,  True, False,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True, False, False,  True, False, False,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True, False,  True,  True, False,  True,  True])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_preds == label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studies",
   "language": "python",
   "name": "studies"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
